# Talking to Ourselves

 This is a project for codecademy's course, [Build Chatbots with Python](https://www.codecademy.com/learn/paths/build-chatbots-with-python) in which I use the Transformer model to build a generative chatbot. With the explosion in popularity of large language models like ChatGPT, generative open-domain chatbots will be necessary to meet the needs of businesses and users in the near and distant future. 

## Requirements
* Python 3.6+
* re
* NumPy
* TensorFlow
* TensorFlow_datasets
* Matplotlib


## Setup
1. Clone the repository.
2. Install the required packages
3. Run the script

##Dataset
This project uses the [Cornell Movie--Dialogs Corpus](https://www.cs.cornell.edu/~cristian/Cornell_Movie-Dialogs_Corpus.html) because it is sufficiently large, rich, and already processed. 

## Contributing

Feel free to fork the repository and submit pull requests with any improvements or bug fixes.

## Author's notes

In another project, I hope to build a more robust chatbot that will be able to simulate conversation with your favorite podcast host. This project serves as a foundation in which I developed a basic understanding of the following topics:
 
 - Classes and their relationships to objects in Python
 - Object functionality and methods
 - Attention as described in the paper [Attention Is All You Need](https://arxiv.org/abs/1706.03762)
 - Encoders, Decoders, Masking, Positional Encoding, Residual Connections, Learning Rates, embeddings, and so much more...
 - Data Preparation for TensorFlow
 
 I find the overall learning process to be a pendulum of hubris and humility. Armed with some understanding of object-oriented programming, several completed natural language analysis projects, and a google search, I felt confident that I could easily and quickly feed some data into a deep learning pipeline and build an effective chatbot. I followed several walkthroughs that used various packages to deploy a chat client, and even one using Redis; but found myself stuck with each option. I reached out to the authors of the articles, received great help, and determined that I had set my scope too large - I needed to start with a model and an interface that I knew would work.
 
 For the model, I followed TensorFlow's tutorial on building [A Transformer Chatbot Tutorial with TensorFlow 2.0](https://blog.tensorflow.org/2019/05/transformer-chatbot-tutorial-with-tensorflow-2.html). For the chat interface, I decided to stick with building a working chat object that would use the Transformer model to generate responses. It thinks I'm cute and that's all I need to feel successful as can be seen in the picture below:
 
 ![sample chat](https://github.com/lindbergag/talkingtoourselves/blob/main/effectivemodel.png)
 
 To help with my understanding of the Transformer architecture, I built, and gave a presentation with animations that was intended to help a lay-person understand the Transformer model. This deeper, more nuanced understanding of the model helped me to think through and design the 'ChatBot' class in the [python script for this project.](https://github.com/lindbergag/talkingtoourselves/blob/main/transformerchatbot.ipynb)
 
 Furthermore, it's helped me to develop the confidence necessary for my next project. In that project, I intend to use a different dataset for the reinforcement learning stage of training an existing large language model and deploy the resulting model using a framework such as Flask or NodeJs.
 
 ## Ethical Concerns
 Generative chatbots give confident answers that are easy to take at face value; however, the bots are equally as confident with wrong answers as they are with right answers. In the coming years, this may lead to several complicated challenges as these models are deployed in services like Bing. The data used to develop large language models wasn't necessarily generated by authors that have explicitly consented to their internet musings being used in this way. Because that source data comes from humans - it can reflect human behavior at its best and at its worst. These systems have the potential to completely re-shape the internet, the economic incentives that support internet businesses, and will pose a significant challenge to the idea of academic meritocracy. For an individual, the best approach to addressing these concerns is to think about how this might change the services they rely-on in the coming years and plan for how their relationship to these services will change. 
 
 Andrew Lindberg
 @lindbergag
 
 
